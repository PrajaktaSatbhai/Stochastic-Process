# Que.1 :- Consider a finite Markov Chain {Xn,n ∈ N} with state space S = 0,1,2,3,4 and TPM is P1 and initial
# probabilities are α = [α0,α1,α2,α3,α4] = [0.1,0.2,0.3,0.2,0.2]. Simulate Xn up to n = 5.

#       [  1    0    0    0    0
#         0.4   0   0.6   0    0
#  P1 =    0   0.5   0   0.5   0
#          0    0   0.2   0   0.8
#          0    0    0    0    1  ]

states=c("0","1","2","3","4")
s=1:5; 
n=5; 
a=c(0.1,0.2,0.3,0.2,0.2);
P=matrix(c(1,0,0,0,0,0.4,0,0.6,0,0,0,0.5,0,0.5,0,0,0,0.2,0,0.8,0,0,0,0,1),ncol=5,byrow = T)
x=rep(0,n+1)
x[1]=sample(s,1,prob=a)
for (i in 1:n)
{
  x[i+1]=sample(s,1,prob=P[x[i],])
}
x
states[x]


# Que.1 :- Consider a finite Markov Chain {Xn,n ∈ N} with state space S = 0,1,2,3,4 and TPM is P1 and initial
# probabilities are α = [α0,α1,α2,α3,α4] = [0.1,0.2,0.3,0.2,0.2]. Simulate Xn up to n = 7.

#       [  1    0    0    0    0
#         0.4   0   0.6   0    0
#  P1 =    0   0.5   0   0.5   0
#          0    0   0.2   0   0.8
#          0    0    0    0    1  ]

states=c("0","1","2","3","4")
s=1:5; 
n=7; 
a=c(0.1,0.2,0.3,0.2,0.2);
P=matrix(c(1,0,0,0,0,0.4,0,0.6,0,0,0,0.5,0,0.5,0,0,0,0.2,0,0.8,0,0,0,0,1),ncol=5,byrow = T)
x=rep(0,n+1)
x[1]=sample(s,1,prob=a)
for (i in 1:n)
{
  x[i+1]=sample(s,1,prob=P[x[i],])
}
x
states[x]


# Que.3 :- Consider a random walk {Xn,n ∈ N} with state space S = {··· ,−3,−2,−1,0,1,2,3,···}. Simulate Xn
# up to n = 7 where P[yi = 1] = 0.55 = 1−P[yi = −1] and X0 = 0

Y=sample(c(-1,1),7,replace=T,prob=c(0.45,0.55))
X=100+cumsum(Y)
X
